{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cde5e45-2ddf-41e9-879d-3f346d1207bd",
   "metadata": {},
   "source": [
    "# FIND DUPLICATES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00a0a0-80fa-4bbd-8728-a3760cb38f90",
   "metadata": {},
   "source": [
    "## Import the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e130536-9e39-4fad-a248-f057ad0708da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-09 19:43:20] HER CSV file last modified: 2025-02-07 17:06:55\n",
      "[2025-02-09 19:43:20] Number of rows in HER CSV file: 44147\n",
      "[2025-02-09 19:43:20] EDS CSV file last modified: 2025-02-07 17:07:43\n",
      "[2025-02-09 19:43:20] Number of rows in EDS CSV file: 76524\n",
      "[2025-02-09 19:43:21] Number of records found for HER in combined dataframe 'data': 44146\n",
      "[2025-02-09 19:43:21] Number of records found for EDS in combined dataframe 'data': 76523\n",
      "[2025-02-09 19:43:21] Total Number of records in dataframe 'data': 120669\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the data types for the columns\n",
    "dtype_dict = {\n",
    "    'ECLID': str,\n",
    "    'First_Occurrence_ECLID': str,\n",
    "    'COMPANY': str,\n",
    "    'UPC': str,\n",
    "    'PUID1': str\n",
    "}\n",
    "\n",
    "# Function to get the last modified timestamp of a file\n",
    "def get_file_timestamp(file_path):\n",
    "    timestamp = os.path.getmtime(file_path)  # Get the last modified time in seconds since epoch\n",
    "    return datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')  # Convert to readable format\n",
    "\n",
    "# Function to log messages to both the console and a log file\n",
    "def log_message(message, log_file='C:/Users/mark.artim/OneDrive - Heritage Distribution Holdings/EclipseDownload/importlog.txt'):\n",
    "    # Get the current timestamp for the log entry\n",
    "    log_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    log_entry = f\"[{log_timestamp}] {message}\\n\"\n",
    "\n",
    "    # Print to the console\n",
    "    print(log_entry, end='')\n",
    "\n",
    "    # Append to the log file\n",
    "    with open(log_file, 'a') as file:\n",
    "        file.write(log_entry)\n",
    "\n",
    "# File paths\n",
    "file_path_HER = 'C:/Users/mark.artim/OneDrive - Heritage Distribution Holdings/EclipseDownload/ProdIDQualityHER.csv'\n",
    "file_path_EDS = 'C:/Users/mark.artim/OneDrive - Heritage Distribution Holdings/EclipseDownload/ProdIDQualityEDS.csv'\n",
    "\n",
    "# Get timestamps\n",
    "timestamp_HER = get_file_timestamp(file_path_HER)\n",
    "timestamp_EDS = get_file_timestamp(file_path_EDS)\n",
    "\n",
    "# Load CSV files\n",
    "data1 = pd.read_csv(file_path_HER, encoding='windows-1252', skiprows=8, dtype=dtype_dict)\n",
    "data1.insert(0, 'COMPANY', 'A-HER')\n",
    "\n",
    "data2 = pd.read_csv(file_path_EDS, encoding='windows-1252', skiprows=8, dtype=dtype_dict)\n",
    "data2.insert(0, 'COMPANY', 'B-EDS')\n",
    "\n",
    "# Count the number of rows in the CSV files\n",
    "with open(file_path_HER, 'r', encoding='windows-1252') as file:\n",
    "    reader = csv.reader(file)\n",
    "    row_count_HER = sum(1 for row in reader) - 8  # Subtract 8 to account for skipped rows\n",
    "\n",
    "with open(file_path_EDS, 'r', encoding='windows-1252') as file:\n",
    "    reader = csv.reader(file)\n",
    "    row_count_EDS = sum(1 for row in reader) - 8  # Subtract 8 to account for skipped rows\n",
    "\n",
    "# Log timestamps and row counts\n",
    "log_message(f\"HER CSV file last modified: {timestamp_HER}\")\n",
    "log_message(f\"Number of rows in HER CSV file: {row_count_HER}\")\n",
    "\n",
    "log_message(f\"EDS CSV file last modified: {timestamp_EDS}\")\n",
    "log_message(f\"Number of rows in EDS CSV file: {row_count_EDS}\")\n",
    "\n",
    "# Append the DataFrames\n",
    "data = pd.concat([data1, data2], ignore_index=True)\n",
    "\n",
    "# Make a copy of the dataframe for finding matches on PUID1 which is Catalog Number!!\n",
    "datac = data.copy()\n",
    "\n",
    "# Log the number of records for EDS versus HER\n",
    "data_EDS = data[(data['COMPANY'] == 'B-EDS')]\n",
    "data_HER = data[(data['COMPANY'] == 'A-HER')]\n",
    "log_message(f\"Number of records found for HER in combined dataframe 'data': {len(data_HER)}\")\n",
    "log_message(f\"Number of records found for EDS in combined dataframe 'data': {len(data_EDS)}\")\n",
    "log_message(f\"Total Number of records in dataframe 'data': {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ddcb64-2e2c-4bb8-87f6-3af8479b1605",
   "metadata": {},
   "source": [
    "## Find UPC Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7362a676-ea12-4d45-80d4-8fb2faa89b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of records in dataframe 'data': 120669\n",
      "Number of rows where UPC_count > 1: 27101\n",
      "Number or rows in data: 120669\n",
      "Now creating the UPC cross reference file C:/Users/mark.artim/Documents/upc.pn.xref.csv\n",
      "Filter for only Ed's records. Number of records: 76523\n",
      "Filter for only UPC_Count > 1. Number of records: 17712\n",
      "The new CSV file, C:/Users/mark.artim/Documents/upc.pn.xref.csv, has been created.\n",
      "        ECLID First_Occurrence_ECLID COMPANY First_Occurrence_COMPANY  \\\n",
      "79795  335684                  77295   B-EDS                    A-HER   \n",
      "79786   21187                  12897   B-EDS                    A-HER   \n",
      "\n",
      "                                   DESC          UPC  UPC_Count BUYLINE  \\\n",
      "79795  VCMA-20ULS-PRO 230V LITTLE GIANT  01012101443        2.0     LTG   \n",
      "79786     RIM-U LG DUAL V UNIV I-M PUMP  01012110705        2.0     LTG   \n",
      "\n",
      "      MatchType BUYLINEX  \n",
      "79795  UPCMATCH      LTG  \n",
      "79786  UPCMATCH      LTG  \n"
     ]
    }
   ],
   "source": [
    "#data.describe()\n",
    "#data.info()\n",
    "\n",
    "print(f\"Total Number of records in dataframe 'data': {len(data)}\")\n",
    "\n",
    "# Calculate the value counts for the 'UPC' column\n",
    "UPC_count = data['UPC'].value_counts()\n",
    "\n",
    "# Map the value counts & MatchType back to the DataFrame\n",
    "data['UPC_Count'] = data['UPC'].map(UPC_count)\n",
    "data['MatchType'] = 'UPCMATCH'\n",
    "\n",
    "# Insert the new column at the specified position\n",
    "data.insert(6, 'UPC_Count', data.pop('UPC_Count'))\n",
    "\n",
    "# SHOW HOW MANY XREFS BASED ON UPC\n",
    "# Condition to check UPC_count > 1\n",
    "condition = data['UPC_Count'] > 1\n",
    "# Count the number of rows that meet the condition\n",
    "count = condition.sum()\n",
    "# Print the count\n",
    "print(f\"Number of rows where UPC_count > 1: {count}\")\n",
    "\n",
    "# Print the number of records found\n",
    "print(f\"Number or rows in data: {len(data)}\")\n",
    "\n",
    "# Create a new column with concatenated values for sorting HER products before Ed's\n",
    "data['Company_UPC'] = data['UPC'] + '-' + data['COMPANY'].astype(str)\n",
    "\n",
    "data['ECLID_INT'] = pd.to_numeric(data['ECLID'], downcast ='signed')\n",
    "data = data.sort_values(by=['Company_UPC', 'ECLID_INT'], ascending=True)\n",
    "\n",
    "# Create a dictionary to store the first occurrence of each UPC\n",
    "first_occurrence = {}\n",
    "first_occurrence_co = {}\n",
    "for index, row in data.iterrows():\n",
    "    if row['UPC'] not in first_occurrence:\n",
    "        first_occurrence[row['UPC']] = row['ECLID']\n",
    "        first_occurrence_co[row['UPC']] = row['COMPANY']\n",
    "\n",
    "# Add a new column to the data based on the first occurrence\n",
    "data['First_Occurrence_ECLID'] = data['UPC'].map(first_occurrence)\n",
    "data['First_Occurrence_COMPANY'] = data['UPC'].map(first_occurrence_co)\n",
    "upcxref = data\n",
    "\n",
    "# Define the CSV file name\n",
    "upc_xref_file_name = 'C:/Users/mark.artim/Documents/upc.pn.xref.csv'\n",
    "\n",
    "# CREATE THE PN XREF FILE\n",
    "print(f\"Now creating the UPC cross reference file {upc_xref_file_name}\")\n",
    "\n",
    "data = data[data['COMPANY'] == 'B-EDS']\n",
    "print(f\"Filter for only Ed's records. Number of records: {len(data)}\")\n",
    "data = data[data['UPC_Count'] > 1]\n",
    "print(f\"Filter for only UPC_Count > 1. Number of records: {len(data)}\")\n",
    "\n",
    "#data1 = pd.read_csv(file_path, encoding='windows-1252', skiprows=8)\n",
    "selected_columns = data[['ECLID', 'First_Occurrence_ECLID', 'COMPANY', 'First_Occurrence_COMPANY', 'DESC', 'UPC', \"UPC_Count\", 'BUYLINE', 'MatchType','BUYLINEX']]\n",
    "#selected_columns['MatchType'] = 'UPCMATCH'\n",
    "# Save the selected columns to a new CSV file\n",
    "selected_columns.to_csv(upc_xref_file_name, index=False)\n",
    "\n",
    "print(f\"The new CSV file, {upc_xref_file_name}, has been created.\")\n",
    "\n",
    "print(selected_columns.head(2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fccb0d-efad-4d57-bb20-4c254e7aeab8",
   "metadata": {},
   "source": [
    "## Alternate UPC Match Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "046ad5da-0682-4cf6-9d01-42328070e97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new CSV file, C:/Users/mark.artim/Documents/upc.pn.xref.csv, has been created.\n",
      "Number of rows in upc.pn.xref.csv file: 17713\n"
     ]
    }
   ],
   "source": [
    "# Calculate the value counts for the 'UPC' column\n",
    "data['UPC_Count'] = data['UPC'].map(data['UPC'].value_counts())\n",
    "\n",
    "# Create a dictionary to store the first occurrence of each UPC\n",
    "first_occurrence_dict = data.drop_duplicates(subset='UPC').set_index('UPC')['ECLID']\n",
    "\n",
    "# Map the first occurrence to the data\n",
    "data['First_Occurrence_ECLID'] = data['UPC'].map(first_occurrence_dict)\n",
    "data['First_Occurrence_COMPANY'] = data['UPC'].map(first_occurrence_co)\n",
    "\n",
    "# Add a match type column\n",
    "data['MatchType'] = 'UPCMATCH'\n",
    "\n",
    "# Filter the data for `B-EDS` and `UPC_Count > 1`\n",
    "filtered_data = data[(data['COMPANY'] == 'B-EDS') & (data['UPC_Count'] > 1)]\n",
    "\n",
    "# Select the relevant columns for the output file\n",
    "selected_columns = filtered_data[\n",
    "    [\n",
    "        'ECLID',\n",
    "        'First_Occurrence_ECLID',\n",
    "        'COMPANY',\n",
    "        'First_Occurrence_COMPANY',\n",
    "        'DESC',\n",
    "        'UPC',\n",
    "        \"UPC_Count\",\n",
    "        'BUYLINE',\n",
    "        'MatchType',\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Define the output file path\n",
    "upc_xref_file_name = 'C:/Users/mark.artim/Documents/upc.pn.xref.csv'\n",
    "\n",
    "# Save the filtered data to the output file\n",
    "selected_columns.to_csv(upc_xref_file_name, index=False)\n",
    "\n",
    "print(f\"The new CSV file, {upc_xref_file_name}, has been created.\")\n",
    "\n",
    "# Count the number of rows in the CSV file cat.pn.xref.csv AFTER removing records in UPC file\n",
    "with open(upc_xref_file_name, 'r', encoding='windows-1252') as file:\n",
    "    reader = csv.reader(file)\n",
    "    row_count = sum(1 for row in reader)\n",
    "\n",
    "print(f\"Number of rows in upc.pn.xref.csv file: {row_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce18f2e-dadd-4182-a912-77bc5d81eff0",
   "metadata": {},
   "source": [
    "## Find CATALOG NUMBER Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "027bd284-ca36-422a-a844-1b07b72b87cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of records in dataframe 'datac': 120669\n",
      "Number or rows in data: 120669\n",
      "datac first record:\n",
      "  COMPANY BUYLINE  ECLID  CAT_Count            CAT_BUYLINE  \\\n",
      "6   A-HER  3TCORP  94157        1.0  3TCORP-1624121-3TCORP   \n",
      "\n",
      "                                DESC  UPC           PUID1       PUID1A PUID2  \\\n",
      "6  3TC.1624121 16 X 24 1/2 X 1 METAL  NaN  3TCORP-1624121  3TC.1624121   NaN   \n",
      "\n",
      "   UPCLGTH    STATUS PRCLINE BUYLINEX     MatchType           Company_CAT  \\\n",
      "6      0.0  NONSTOCK  3TCORP      NaN  CATALOGMATCH  3TCORP-1624121-A-HER   \n",
      "\n",
      "   ECLID_INT  \n",
      "6    94157.0  \n",
      "Now creating the UPC cross reference file C:/Users/mark.artim/Documents/cat.pn.xref.csv\n",
      "Filter for only Ed's records. Number of records: 76523\n",
      "Filter for only CAT_Count > 1. Number of records: 22183\n",
      "The new CSV file, C:/Users/mark.artim/Documents/cat.pn.xref.csv, has been created.\n",
      "        ECLID First_Occurrence_ECLID COMPANY First_Occurrence_COMPANY  \\\n",
      "44153   99187                  99187   B-EDS                    B-EDS   \n",
      "44154  139941                  99187   B-EDS                    B-EDS   \n",
      "\n",
      "                                 DESC      PUID1  CAT_Count BUYLINE  \\\n",
      "44153    1000P 1 GAL POLY SPRAYER ACE  ACE-1000P        2.0     ACE   \n",
      "44154  1000P ACE CHEMICALS HEAVY-DUTY  ACE-1000P        2.0     ACE   \n",
      "\n",
      "          MatchType BUYLINEX  \n",
      "44153  CATALOGMATCH   CN-ACE  \n",
      "44154  CATALOGMATCH      ACE  \n",
      "The new CSV file, C:/Users/mark.artim/Documents/cat.pn.xref.csv, has been created.\n",
      "Number of rows in cat.pn.xref.csv file: 22184\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Number of records in dataframe 'datac': {len(datac)}\")\n",
    "\n",
    "# Calculate the value counts for the 'UPC' column\n",
    "CAT_count = datac['PUID1'].value_counts()\n",
    "\n",
    "#Map the value counts & match type back to the DataFrame\n",
    "datac['CAT_Count'] = datac['PUID1'].map(CAT_count)\n",
    "datac['MatchType'] = 'CATALOGMATCH'\n",
    "\n",
    "# Print the number of records found\n",
    "print(f\"Number or rows in data: {len(datac)}\")\n",
    "\n",
    "# Create a new column with concatenated values for sorting HER products before Ed's\n",
    "datac['Company_CAT'] = datac['PUID1'] + '-' + datac['COMPANY'].astype(str)\n",
    "datac['ECLID_INT'] = pd.to_numeric(datac['ECLID'], downcast ='signed')\n",
    "datac['CAT_BUYLINE'] = datac['PUID1'] + '-' + datac['BUYLINE']\n",
    "\n",
    "# Sort by the new column\n",
    "datac = datac.sort_values(by=['CAT_BUYLINE', 'ECLID_INT'])\n",
    "print(\"datac first record:\")\n",
    "\n",
    "\n",
    "# Calculate the value counts for the 'PUID1_BUYLINE' column\n",
    "CAT_Count = datac['CAT_BUYLINE'].value_counts()\n",
    "\n",
    "# Map the value counts back to the DataFrame\n",
    "#datac['CAT_Count'] = datac['CAT_BUYLINE'].map(CAT_Count)\n",
    "\n",
    "# Insert the new column at the specified position\n",
    "datac.insert(3, 'CAT_Count', datac.pop('CAT_Count'))\n",
    "datac.insert(4, 'CAT_BUYLINE', datac.pop('CAT_BUYLINE'))\n",
    "print(datac.head(1))\n",
    "\n",
    "\n",
    "# Create a dictionary to store the first occurrence of each UPC\n",
    "first_occurrence = {}\n",
    "first_occurrence_co = {}\n",
    "for index, row in datac.iterrows():\n",
    "    if row['CAT_BUYLINE'] not in first_occurrence:\n",
    "        first_occurrence[row['CAT_BUYLINE']] = row['ECLID']\n",
    "        first_occurrence_co[row['CAT_BUYLINE']] = row['COMPANY']\n",
    "\n",
    "# Add a new column to the data based on the first occurrence\n",
    "datac['First_Occurrence_ECLID'] = datac['CAT_BUYLINE'].map(first_occurrence)\n",
    "datac['First_Occurrence_COMPANY'] = datac['CAT_BUYLINE'].map(first_occurrence_co)\n",
    "catxref = datac\n",
    "\n",
    "# Define the CSV file name\n",
    "cat_xref_file_name = 'C:/Users/mark.artim/Documents/cat.pn.xref.csv'\n",
    "\n",
    "# CREATE THE PN XREF FILE\n",
    "print(f\"Now creating the UPC cross reference file {cat_xref_file_name}\")\n",
    "\n",
    "datac = datac[datac['COMPANY'] == 'B-EDS']\n",
    "print(f\"Filter for only Ed's records. Number of records: {len(datac)}\")\n",
    "datac = datac[datac['CAT_Count'] > 1]\n",
    "print(f\"Filter for only CAT_Count > 1. Number of records: {len(datac)}\")\n",
    "\n",
    "#data1 = pd.read_csv(file_path, encoding='windows-1252', skiprows=8)\n",
    "selected_columns = datac[['ECLID', 'First_Occurrence_ECLID', 'COMPANY', 'First_Occurrence_COMPANY', 'DESC', 'PUID1', \"CAT_Count\", 'BUYLINE', 'MatchType','BUYLINEX']]\n",
    "#selected_columns['MatchType'] = 'CATALOGMATCH'\n",
    "# Save the selected columns to a new CSV file\n",
    "selected_columns.to_csv(cat_xref_file_name, index=False)\n",
    "\n",
    "print(f\"The new CSV file, {cat_xref_file_name}, has been created.\")\n",
    "\n",
    "print(selected_columns.head(2))\n",
    "\n",
    "print(f\"The new CSV file, {cat_xref_file_name}, has been created.\")\n",
    "\n",
    "# Count the number of rows in the CSV file cat.pn.xref.csv AFTER removing records in UPC file\n",
    "with open(cat_xref_file_name, 'r', encoding='windows-1252') as file:\n",
    "    reader = csv.reader(file)\n",
    "    row_count = sum(1 for row in reader)\n",
    "\n",
    "print(f\"Number of rows in cat.pn.xref.csv file: {row_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6e6ae6-aed7-4f2c-a0cf-f3625b18f6c9",
   "metadata": {},
   "source": [
    "## Remove entries in the CATALOG match file that are already in the UPC file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60e3ab4b-21b5-4630-adc6-cac17bd393b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in cat.pn.xref.csv file: 22184\n",
      "Records removed. Filtered file saved as 'filtered_cat.pn.xref.csv'\n",
      "Number of rows in cat.pn.xref.csv file: 9499\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Load the two CSV files\n",
    "cat_file = \"C:/Users/mark.artim/Documents/cat.pn.xref.csv\"\n",
    "upc_file = \"C:/Users/mark.artim/Documents/upc.pn.xref.csv\"\n",
    "\n",
    "# Count the number of rows in the CSV file cat.pn.xref.csv\n",
    "with open(cat_file, 'r', encoding='windows-1252') as file:\n",
    "    reader = csv.reader(file)\n",
    "    row_count = sum(1 for row in reader)\n",
    "print(f\"Number of rows in cat.pn.xref.csv file: {row_count}\")\n",
    "\n",
    "cat_df = pd.read_csv(cat_file, header=None)  # Load cat.pn.xref.csv\n",
    "upc_df = pd.read_csv(upc_file, header=None)  # Load upc.pn.xref.csv\n",
    "\n",
    "# Assuming the first column in both files is column 0\n",
    "cat_first_column = cat_df[0]\n",
    "upc_first_column = upc_df[0]\n",
    "\n",
    "# Filter rows in cat_df where the first column value is NOT in the upc first column\n",
    "filtered_cat_df = cat_df[~cat_df[0].isin(upc_first_column)]\n",
    "\n",
    "# Save the filtered data back to the same file or a new file\n",
    "new_cat_file = \"C:/Users/mark.artim/Documents/filtered_cat.pn.xref.csv\"\n",
    "filtered_cat_df.to_csv(new_cat_file, index=False, header=False)\n",
    "\n",
    "print(\"Records removed. Filtered file saved as 'filtered_cat.pn.xref.csv'\")\n",
    "\n",
    "# Count the number of rows in the CSV file cat.pn.xref.csv AFTER removing records in UPC file\n",
    "with open(new_cat_file, 'r', encoding='windows-1252') as file:\n",
    "    reader = csv.reader(file)\n",
    "    row_count = sum(1 for row in reader)\n",
    "\n",
    "print(f\"Number of rows in cat.pn.xref.csv file: {row_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec516e3-713d-4520-ac33-8ba149b0a91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212259f-8110-4e5e-a783-ad7419e84820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
